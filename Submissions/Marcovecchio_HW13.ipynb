{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('hastools': conda)",
   "metadata": {
    "interpreter": {
     "hash": "6dc1828b489e8e06dcbc2ea37c1bcec27406c1a986f1613d06237ca1cf460e88"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "Alexa Marcovecchio\n",
    "\n",
    "Assignment 13\n",
    "\n",
    "November 23, 2020\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Import packages and define functions\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import fiona\n",
    "import contextily as ctx\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def getForecastDates():\n",
    "    \"\"\"Get dataframe of forecast dates from csv file.\n",
    "\n",
    "    -------------------------------------------------\n",
    "    Parameters: None\n",
    "\n",
    "    -------------------------------------------------\n",
    "    Outputs:\n",
    "    forecast dates = dataframe\n",
    "                     contains columns with start and end\n",
    "                     dates split up into\n",
    "                     year, month, and day\n",
    "    \"\"\"\n",
    "    #  Read in the forecast dates for each week from csv\n",
    "    filename = os.path.join('../data',\n",
    "                            \"Seasonal_Forecast_Dates.csv\")\n",
    "    forecast_dates = pd.read_csv(filename, skiprows=1,\n",
    "                                 names=['week', 'start_date', 'end_date'])\n",
    "    forecast_dates[[\"start_year\", \"start_month\", \"start_day\"]] \\\n",
    "        = forecast_dates[\"start_date\"].\\\n",
    "        astype(str).str.split(\"-\", expand=True)\n",
    "\n",
    "    # split forecast start and end dates into year, month, and day\n",
    "    forecast_dates['start_year'] = forecast_dates['start_year'].astype(int)\n",
    "    forecast_dates['start_month'] = forecast_dates['start_month'].astype(int)\n",
    "    forecast_dates['start_day'] = forecast_dates['start_day'].astype(int)\n",
    "    forecast_dates[[\"end_year\", \"end_month\", \"end_day\"]] \\\n",
    "        = forecast_dates[\"end_date\"].\\\n",
    "        astype(str).str.split(\"-\", expand=True)\n",
    "    forecast_dates['end_year'] = forecast_dates['end_year'].astype(int)\n",
    "    forecast_dates['end_month'] = forecast_dates['end_month'].astype(int)\n",
    "    forecast_dates['end_day'] = forecast_dates['end_day'].astype(int)\n",
    "\n",
    "    return forecast_dates\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 3,
   "outputs": []
  },
  {
   "source": [
    "Plot recent streamflow data to determine 1 and 2 week streamflow forecasts.\n",
    "\n",
    "![](assets/Marcovecchio_HW13_lineplot.png)\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data into a pandas dataframe\n",
    "url_usgs = 'https://waterdata.usgs.gov/nwis/dv?cb_00060=on' \\\n",
    "           '&format=rdb&site_no=09506000&referred_module=sw' \\\n",
    "           '&period=&begin_date=1989-01-01&end_date=2020-11-21'\n",
    "\n",
    "data = pd.read_table(url_usgs, skiprows=30, names=['agency_cd', 'site_no',\n",
    "                                                   'datetime', 'flow', 'code'],\n",
    "                     parse_dates=['datetime'])\n",
    "\n",
    "# Expand the dates to year month day\n",
    "data['year'] = pd.DatetimeIndex(data['datetime']).year\n",
    "data['month'] = pd.DatetimeIndex(data['datetime']).month\n",
    "data['day'] = pd.DatetimeIndex(data['datetime']).dayofweek\n",
    "data['dayofweek'] = pd.DatetimeIndex(data['datetime']).dayofweek\n",
    "\n",
    "# Aggregate flow values to weekly\n",
    "flow_weekly = data.resample(\"W\", on='datetime').mean()\n",
    "\n",
    "# Plot daily streamflow\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(data['datetime'].tail(14), data['flow'].tail(14), color='C0')\n",
    "ax.set(title=\"Streamflow from Past Two Weeks\",\n",
    "       xlabel=\"Date\", ylabel=\"Daily Flow [cfs]\")\n",
    "ax.legend()\n",
    "fig.set_size_inches(10, 6)\n",
    "\n",
    "# Plot year to date streamflow\n",
    "fig, ax = plt.subplots()\n",
    "ax.boxplot(data['flow'].tail(92))\n",
    "ax.set(title=\"Streamflow Since Start of Semester\",\n",
    "       ylabel=\"Daily Flow [cfs]\")\n",
    "ax.xaxis.set_visible(False)\n",
    "fig.set_size_inches(10, 6)\n",
    "\n",
    "print('Based on streamflow plots:')\n",
    "print('week 1 forecast: 153 cfs')\n",
    "print('week 2 forecast: 150 cfs')"
   ]
  },
  {
   "source": [
    "Make map of September 2020 mean average precipitation in order to determine where the majority of precipitation is falling."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read ncdf precip file\n",
    "data_path = os.path.join('../data',\n",
    "                         'MERRA2_401.tavgM_2d_int_Nx.202009.SUB.nc')\n",
    "\n",
    "# Read in the dataset as an x-array\n",
    "dataset = xr.open_dataset(data_path)\n",
    "\n",
    "# Sum different types of precip\n",
    "PREC = dataset['PRECCU'] + dataset['PRECLS'] + dataset['PRECSN']\n",
    "\n",
    "# convert to mm/day\n",
    "PREC.values = PREC.values*86400.\n",
    "\n",
    "# slice to fit crs of HUC6\n",
    "PREC_az = PREC.sel(lat=slice(30, 40.5),\n",
    "                   lon=slice(-118, -107))\n",
    "\n",
    "file = os.path.join('../data', 'WBD_15_HU2_GDB.gdb')\n",
    "fiona.listlayers(file)\n",
    "HUC6 = gpd.read_file(file, layer=\"WBDHU6\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 8))\n",
    "HUC6.boundary.plot(ax=ax, color=None,\n",
    "                   edgecolor='lightgreen',\n",
    "                   linewidth=0.7,\n",
    "                   zorder=2,\n",
    "                   label='HUC6')\n",
    "ctx.add_basemap(ax, crs=HUC6.crs, zorder=0)\n",
    "PREC_az.plot(ax=ax,\n",
    "             zorder=1,\n",
    "             alpha=0.5,\n",
    "             label='Precipitation (mm/day)')\n",
    "ax.set_title('AZ Watershed Mean Precipitation \\n September 2020 (mm/day)')\n",
    "ax.legend()\n",
    "ax.axis('off')"
   ]
  },
  {
   "source": [
    "Prepare 16 week forecast using 30 year averaging method."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data from beginning of semester\n",
    "url_usgs_16wk = 'https://waterdata.usgs.gov/nwis/dv?cb_00060=on' \\\n",
    "           '&format=rdb&site_no=09506000&referred_module=sw' \\\n",
    "           '&period=&begin_date=1989-01-01&end_date=2020-08-29'\n",
    "data_16wk = pd.read_table(url_usgs_16wk, skiprows=30, names=['agency_cd',\n",
    "                                                             'site_no',\n",
    "                                                             'datetime',\n",
    "                                                             'flow', 'code'],\n",
    "                          parse_dates=['datetime'])\n",
    "\n",
    "# Expand the dates to year month day and set them as integers\n",
    "data_16wk[[\"year\", \"month\", \"day\"]] = data_16wk[\"datetime\"].\\\n",
    "                                 astype(str).str.split(\"-\", expand=True)\n",
    "data_16wk['year'] = data_16wk['year'].astype(int)  # year integer\n",
    "data_16wk['month'] = data_16wk['month'].astype(int)  # month integer\n",
    "data_16wk['day'] = data_16wk['day'].astype(int)  # day integer\n",
    "\n",
    "# get annual average streamflow\n",
    "year_means = np.zeros((32, 2))\n",
    "for j in range(1989, 2021):\n",
    "    year_means[j-1989, 0] = j\n",
    "    year_means[j-1989, 1] = data_16wk[data_16wk.year == j].flow.mean()\n",
    "\n",
    "# find the five driest years on record using nsmallest\n",
    "driest = pd.DataFrame(year_means, columns=['year', 'mean']).\\\n",
    "         nsmallest(5, 'mean')\n",
    "driest.index = range(5)\n",
    "driest['year'] = driest['year'].astype(int)\n",
    "\n",
    "# make a dataframe that only contains data from the driest years\n",
    "dry_years_data = data_16wk[(data_16wk.year == driest.year[0]) |\n",
    "                           (data_16wk.year == driest.year[1]) |\n",
    "                           (data_16wk.year == driest.year[2]) |\n",
    "                           (data_16wk.year == driest.year[3]) |\n",
    "                           (data_16wk.year == driest.year[4])\n",
    "                           ]\n",
    "\n",
    "forecast_dates = getForecastDates()\n",
    "\n",
    "# initialize list for weekly forecasts\n",
    "forecasts = []\n",
    "\n",
    "# go through each week and get the means for each week\n",
    "for i in range(16):\n",
    "\n",
    "    # if the forecast week starts and ends in different months\n",
    "    if (forecast_dates.start_month[i] != forecast_dates.end_month[i]):\n",
    "        # set the date of the last day of the month\n",
    "        if(forecast_dates.start_month[i] == 8):\n",
    "            last_day = 31\n",
    "        if(forecast_dates.start_month[i] == 9):\n",
    "            last_day = 30\n",
    "        if(forecast_dates.start_month[i] == 10):\n",
    "            last_day = 31\n",
    "        if(forecast_dates.start_month[i] == 11):\n",
    "            last_day = 30\n",
    "        # take average of all dates within the forecast week during dry years\n",
    "        wk_mean = dry_years_data[((dry_years_data.month ==\n",
    "                                   forecast_dates.start_month[i]) &\n",
    "                                 (dry_years_data.day >=\n",
    "                                  forecast_dates.start_day[i]) &\n",
    "                                 (dry_years_data.day <= last_day)) |\n",
    "                                 ((dry_years_data.month ==\n",
    "                                  forecast_dates.end_month[i]) &\n",
    "                                 (dry_years_data.day >= 1) &\n",
    "                                 (dry_years_data.day <=\n",
    "                                  forecast_dates.end_day[i]))].flow.mean()\n",
    "        # add weekly mean to forecast lists\n",
    "        forecasts.append(wk_mean)\n",
    "\n",
    "    # if the forecast week starts and ends in the same month\n",
    "    else:\n",
    "        # take average of all dates within forecast week during dry years\n",
    "        wk_mean = dry_years_data[(dry_years_data.month ==\n",
    "                                  forecast_dates.start_month[i]) &\n",
    "                                 (dry_years_data.day >=\n",
    "                                  forecast_dates.start_day[i]) &\n",
    "                                 (dry_years_data.day <=\n",
    "                                  forecast_dates.end_day[i])].flow.mean()\n",
    "        # add weekly mean to forecast lists\n",
    "        forecasts.append(wk_mean)\n",
    "\n",
    "print('Weekly Forecasts:', forecasts)"
   ]
  }
 ]
}